{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T10:21:07.069782Z",
     "start_time": "2020-10-02T10:21:04.449457Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "os.chdir('..')\n",
    "from twitterED.utilities.utils import cleaning, tokenizer,encoding_data,get_length\n",
    "from twitterED.network.model import BERT\n",
    "label_dict = {'bot': 0, 'human': 1}\n",
    "from torch.utils.data import TensorDataset ,DataLoader\n",
    "import torch\n",
    "from twitterED.utilities.prediction import predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T10:21:24.009229Z",
     "start_time": "2020-10-02T10:21:23.961096Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Username</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Date of tweet</th>\n",
       "      <th>Time of tweet</th>\n",
       "      <th>Tweet_Type</th>\n",
       "      <th>Location</th>\n",
       "      <th>Set 1(fully cleaned)</th>\n",
       "      <th>Pred_int</th>\n",
       "      <th>account</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1307816586410100000</td>\n",
       "      <td>_____811_______</td>\n",
       "      <td>RT  :   Ah yes, the public who failed care hom...</td>\n",
       "      <td>20/09/2020</td>\n",
       "      <td>23:59:06</td>\n",
       "      <td>ReTweet</td>\n",
       "      <td>Birmingham, England</td>\n",
       "      <td>ye public fail care home support cum durham tr...</td>\n",
       "      <td>0</td>\n",
       "      <td>personal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1307816458462850000</td>\n",
       "      <td>DeuxLeopardsdor</td>\n",
       "      <td>RT  :   Is it possible that Dido Harding and h...</td>\n",
       "      <td>20/09/2020</td>\n",
       "      <td>23:58:36</td>\n",
       "      <td>ReTweet</td>\n",
       "      <td>Europe</td>\n",
       "      <td>dido hard husband john penros nh overwhelm pus...</td>\n",
       "      <td>0</td>\n",
       "      <td>personal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1307816022834110000</td>\n",
       "      <td>MsKinLondon</td>\n",
       "      <td>RT  :   Ah yes, the public who failed care hom...</td>\n",
       "      <td>20/09/2020</td>\n",
       "      <td>23:56:52</td>\n",
       "      <td>ReTweet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ye public fail care home support cum durham tr...</td>\n",
       "      <td>0</td>\n",
       "      <td>personal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1307815890730330000</td>\n",
       "      <td>carne_sean</td>\n",
       "      <td>RT  :   Ah yes, the public who failed care hom...</td>\n",
       "      <td>20/09/2020</td>\n",
       "      <td>23:56:21</td>\n",
       "      <td>ReTweet</td>\n",
       "      <td>Laaaandan</td>\n",
       "      <td>ye public fail care home support cum durham tr...</td>\n",
       "      <td>0</td>\n",
       "      <td>personal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1307815521312800000</td>\n",
       "      <td>OllyMursgirl42</td>\n",
       "      <td>Well, I was homeless at 15 then in my 20s wi...</td>\n",
       "      <td>20/09/2020</td>\n",
       "      <td>23:54:52</td>\n",
       "      <td>Tweet</td>\n",
       "      <td>Bournemouth, England</td>\n",
       "      <td>homeless zero live hardship children mental he...</td>\n",
       "      <td>0</td>\n",
       "      <td>personal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             Tweet ID         Username  \\\n",
       "0           0  1307816586410100000  _____811_______   \n",
       "1           1  1307816458462850000  DeuxLeopardsdor   \n",
       "2           2  1307816022834110000      MsKinLondon   \n",
       "3           3  1307815890730330000       carne_sean   \n",
       "4           4  1307815521312800000   OllyMursgirl42   \n",
       "\n",
       "                                               Tweet Date of tweet  \\\n",
       "0  RT  :   Ah yes, the public who failed care hom...    20/09/2020   \n",
       "1  RT  :   Is it possible that Dido Harding and h...    20/09/2020   \n",
       "2  RT  :   Ah yes, the public who failed care hom...    20/09/2020   \n",
       "3  RT  :   Ah yes, the public who failed care hom...    20/09/2020   \n",
       "4    Well, I was homeless at 15 then in my 20s wi...    20/09/2020   \n",
       "\n",
       "  Time of tweet Tweet_Type              Location  \\\n",
       "0      23:59:06    ReTweet   Birmingham, England   \n",
       "1      23:58:36    ReTweet                Europe   \n",
       "2      23:56:52    ReTweet                   NaN   \n",
       "3      23:56:21    ReTweet             Laaaandan   \n",
       "4      23:54:52      Tweet  Bournemouth, England   \n",
       "\n",
       "                                Set 1(fully cleaned)  Pred_int   account  \n",
       "0  ye public fail care home support cum durham tr...         0  personal  \n",
       "1  dido hard husband john penros nh overwhelm pus...         0  personal  \n",
       "2  ye public fail care home support cum durham tr...         0  personal  \n",
       "3  ye public fail care home support cum durham tr...         0  personal  \n",
       "4  homeless zero live hardship children mental he...         0  personal  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_infr = pd.read_csv('../../TwitterProject/Pytorch/Account_Classification/14Sep-20Sep.csv',header=0)\n",
    "df_infr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T10:21:34.941780Z",
     "start_time": "2020-10-02T10:21:34.744561Z"
    }
   },
   "outputs": [],
   "source": [
    "df_infr['Tweet']=df_infr['Tweet'].apply(cleaning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T10:21:49.836271Z",
     "start_time": "2020-10-02T10:21:47.111486Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "maximum length of tweet:74\n"
     ]
    }
   ],
   "source": [
    "max_len = max(df_infr['Tweet'].apply(get_length))\n",
    "print (f'maximum length of tweet:{max_len}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T10:22:03.110959Z",
     "start_time": "2020-10-02T10:22:00.295724Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ehsan\\.conda\\envs\\emodetection\\lib\\site-packages\\transformers\\tokenization_utils_base.py:1770: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  FutureWarning,\n"
     ]
    }
   ],
   "source": [
    "infr_data = df_infr.Tweet.values\n",
    "encoded_data_infer = encoding_data(infr_data, max_len = max_len)\n",
    "#encoding process above returns dictionaries. We grab input ID tokens, attention mask, and labels from this\n",
    "input_ids_infer = encoded_data_infer['input_ids'] #return each sentence as a #\n",
    "attention_masks_infer = encoded_data_infer['attention_mask'] #returns a pytorch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T10:22:33.594037Z",
     "start_time": "2020-10-02T10:22:33.576041Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_infr = TensorDataset(input_ids_infer, attention_masks_infer)\n",
    "dataloader_infr = DataLoader(dataset_infr,batch_size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T10:22:47.876666Z",
     "start_time": "2020-10-02T10:22:44.119696Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = BERT(label_dict=label_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T10:25:12.795301Z",
     "start_time": "2020-10-02T10:25:12.744424Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T10:25:24.168768Z",
     "start_time": "2020-10-02T10:25:20.359112Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = './wieght/botdtc/Epoch-2.model'\n",
    "model.load_state_dict(torch.load(model_path))\n",
    "\n",
    "model.eval()\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T10:25:27.947430Z",
     "start_time": "2020-10-02T10:25:27.927431Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bot'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i2c = lambda i: [k for k,v in label_dict.items() if v ==i][0]\n",
    "i2c(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T10:26:07.645924Z",
     "start_time": "2020-10-02T10:25:36.950685Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e75c729da6de44afa992e50da85f52df",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=363.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prediction = predict(dataloader_infr, model=model, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T10:26:09.237812Z",
     "start_time": "2020-10-02T10:26:09.144299Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Tweet ID</th>\n",
       "      <th>Username</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Date of tweet</th>\n",
       "      <th>Time of tweet</th>\n",
       "      <th>Tweet_Type</th>\n",
       "      <th>Location</th>\n",
       "      <th>Set 1(fully cleaned)</th>\n",
       "      <th>Pred_int</th>\n",
       "      <th>account</th>\n",
       "      <th>acc_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1307816586410100000</td>\n",
       "      <td>_____811_______</td>\n",
       "      <td>rt ah yes the public who failed care homes sup...</td>\n",
       "      <td>20/09/2020</td>\n",
       "      <td>23:59:06</td>\n",
       "      <td>ReTweet</td>\n",
       "      <td>Birmingham, England</td>\n",
       "      <td>ye public fail care home support cum durham tr...</td>\n",
       "      <td>0</td>\n",
       "      <td>personal</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1307816458462850000</td>\n",
       "      <td>DeuxLeopardsdor</td>\n",
       "      <td>rt is it possible that dido harding and her hu...</td>\n",
       "      <td>20/09/2020</td>\n",
       "      <td>23:58:36</td>\n",
       "      <td>ReTweet</td>\n",
       "      <td>Europe</td>\n",
       "      <td>dido hard husband john penros nh overwhelm pus...</td>\n",
       "      <td>0</td>\n",
       "      <td>personal</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1307816022834110000</td>\n",
       "      <td>MsKinLondon</td>\n",
       "      <td>rt ah yes the public who failed care homes sup...</td>\n",
       "      <td>20/09/2020</td>\n",
       "      <td>23:56:52</td>\n",
       "      <td>ReTweet</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ye public fail care home support cum durham tr...</td>\n",
       "      <td>0</td>\n",
       "      <td>personal</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1307815890730330000</td>\n",
       "      <td>carne_sean</td>\n",
       "      <td>rt ah yes the public who failed care homes sup...</td>\n",
       "      <td>20/09/2020</td>\n",
       "      <td>23:56:21</td>\n",
       "      <td>ReTweet</td>\n",
       "      <td>Laaaandan</td>\n",
       "      <td>ye public fail care home support cum durham tr...</td>\n",
       "      <td>0</td>\n",
       "      <td>personal</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1307815521312800000</td>\n",
       "      <td>OllyMursgirl42</td>\n",
       "      <td>well i was homeless at then in my s with zero ...</td>\n",
       "      <td>20/09/2020</td>\n",
       "      <td>23:54:52</td>\n",
       "      <td>Tweet</td>\n",
       "      <td>Bournemouth, England</td>\n",
       "      <td>homeless zero live hardship children mental he...</td>\n",
       "      <td>0</td>\n",
       "      <td>personal</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0             Tweet ID         Username  \\\n",
       "0           0  1307816586410100000  _____811_______   \n",
       "1           1  1307816458462850000  DeuxLeopardsdor   \n",
       "2           2  1307816022834110000      MsKinLondon   \n",
       "3           3  1307815890730330000       carne_sean   \n",
       "4           4  1307815521312800000   OllyMursgirl42   \n",
       "\n",
       "                                               Tweet Date of tweet  \\\n",
       "0  rt ah yes the public who failed care homes sup...    20/09/2020   \n",
       "1  rt is it possible that dido harding and her hu...    20/09/2020   \n",
       "2  rt ah yes the public who failed care homes sup...    20/09/2020   \n",
       "3  rt ah yes the public who failed care homes sup...    20/09/2020   \n",
       "4  well i was homeless at then in my s with zero ...    20/09/2020   \n",
       "\n",
       "  Time of tweet Tweet_Type              Location  \\\n",
       "0      23:59:06    ReTweet   Birmingham, England   \n",
       "1      23:58:36    ReTweet                Europe   \n",
       "2      23:56:52    ReTweet                   NaN   \n",
       "3      23:56:21    ReTweet             Laaaandan   \n",
       "4      23:54:52      Tweet  Bournemouth, England   \n",
       "\n",
       "                                Set 1(fully cleaned)  Pred_int   account  \\\n",
       "0  ye public fail care home support cum durham tr...         0  personal   \n",
       "1  dido hard husband john penros nh overwhelm pus...         0  personal   \n",
       "2  ye public fail care home support cum durham tr...         0  personal   \n",
       "3  ye public fail care home support cum durham tr...         0  personal   \n",
       "4  homeless zero live hardship children mental he...         0  personal   \n",
       "\n",
       "  acc_type  \n",
       "0    human  \n",
       "1    human  \n",
       "2    human  \n",
       "3    human  \n",
       "4    human  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_infr['acc_type']=prediction\n",
    "df_infr['acc_type']=df_infr['acc_type'].apply(i2c)\n",
    "df_infr.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-10-02T10:26:20.525032Z",
     "start_time": "2020-10-02T10:26:19.831037Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ax =df_infr['acc_type'].value_counts().plot.bar(x='lab', y='val', rot=0,color = list('rgbkymc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
